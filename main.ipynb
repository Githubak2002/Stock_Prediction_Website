{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write a code that read data from ticker.txt file in which the stock ticker symbol is situated , the this code goes to data folder inside which there are two folder first is stock_news_data and other one is stock_price_data . inside the stock_news data there is are .csv file name like f\"{stock_symbol}_sentiments.csv\" where the data is like date,mean_sentiment\n",
    "2024-01-01,0.42857142857142855\n",
    "2024-01-02,0.32634920634920633\n",
    "2024-01-03,-0.10386363636363635\n",
    "2024-01-04,0.15928571428571428\n",
    "2024-01-05,0.16\n",
    "2024-01-06,0.15000000000000002 . so now read this data as a dataframe read all the files and then there is other folder named stock_price_data go inside it in there there will be bunch of .json data file . with names f\"{stock_symbol}_data.json\" the data inside it look like this {\n",
    "    \"ticker\": \"AAPL\",\n",
    "    \"queryCount\": 791,\n",
    "    \"resultsCount\": 791,\n",
    "    \"adjusted\": true,\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"v\": 143285672.0,\n",
    "            \"vw\": 129.7326,\n",
    "            \"o\": 133.52,\n",
    "            \"c\": 129.41,\n",
    "            \"h\": 133.6116,\n",
    "            \"l\": 126.76,\n",
    "            \"t\": 1609736400000,\n",
    "            \"n\": 1310217\n",
    "        },\n",
    "        {\n",
    "            \"v\": 97664898.0,\n",
    "            \"vw\": 130.7179,\n",
    "            \"o\": 128.89,\n",
    "            \"c\": 131.01,\n",
    "            \"h\": 131.74,\n",
    "            \"l\": 128.43,\n",
    "            \"t\": 1609822800000,\n",
    "            \"n\": 707577\n",
    "        },..\n",
    "where symbols stand for c*number\n",
    "The close price for the symbol in the given time period.\n",
    "\n",
    "h*number\n",
    "The highest price for the symbol in the given time period.\n",
    "\n",
    "l*number\n",
    "The lowest price for the symbol in the given time period.\n",
    "\n",
    "ninteger\n",
    "The number of transactions in the aggregate window.\n",
    "\n",
    "o*number\n",
    "The open price for the symbol in the given time period.\n",
    "\n",
    "otcboolean\n",
    "Whether or not this aggregate is for an OTC ticker. This field will be left off if false.\n",
    "\n",
    "t*integer\n",
    "The Unix Msec timestamp for the start of the aggregate window.\n",
    "\n",
    "v*number\n",
    "The trading volume of the symbol in the given time period.\n",
    "\n",
    "vwnumber\n",
    "The volume weighted average price.\n",
    "\n",
    "So loop over this data  and make a pandas df out of it and merge with the df we got from the for the setiment file after converting both of their index to datetime format . The final output should look like this . date , Volume,Volume Weighted,Open,Close,High,Low,Count,mean_sentiment\n",
    "2024-01-01,87493432.0,43.7151,43.54,43.5575,43.9675,43.4875,158854,0.20653064574314578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def read_sentiment_data(stock_symbol):\n",
    "    file_path = f\"data/stock_news_data/{stock_symbol}_sentiments.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"No sentiment data found for {stock_symbol}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def read_price_data(stock_symbol):\n",
    "    file_path = f\"data/stock_price_data/{stock_symbol}_data.json\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            results = data.get(\"results\", [])\n",
    "            df = pd.DataFrame(results)\n",
    "            df[\"date\"] = pd.to_datetime(df[\"t\"], unit=\"ms\")\n",
    "            df.set_index(\"date\", inplace=True)\n",
    "            df.drop(columns=[\"t\"], inplace=True)\n",
    "            # Rename columns to full form\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    \"v\": \"Volume\",\n",
    "                    \"vw\": \"Volume Weighted\",\n",
    "                    \"o\": \"Open\",\n",
    "                    \"c\": \"Close\",\n",
    "                    \"h\": \"High\",\n",
    "                    \"l\": \"Low\",\n",
    "                    \"n\": \"Count\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "            return df\n",
    "    else:\n",
    "        print(f\"No price data found for {stock_symbol}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def merge_data(stock_symbols):\n",
    "    for stock_symbol in stock_symbols:\n",
    "        final_df = pd.DataFrame()\n",
    "        sentiment_df = read_sentiment_data(stock_symbol)\n",
    "        price_df = read_price_data(stock_symbol)\n",
    "        if not sentiment_df.empty and not price_df.empty:\n",
    "            # Resample price data to daily frequency to align with sentiment data\n",
    "            price_df = price_df.resample(\"D\").mean()\n",
    "            # Merge sentiment and price data\n",
    "            merged_df = pd.merge(\n",
    "                sentiment_df, price_df, how=\"inner\", left_index=True, right_index=True\n",
    "            )\n",
    "            # Remove rows with data of the current day\n",
    "            today_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "            merged_df = merged_df[merged_df.index != today_date]\n",
    "            # Fill short gaps with forward fill\n",
    "            merged_df = merged_df.ffill(\n",
    "                limit=3\n",
    "            )  # Limit defines the maximum number of consecutive NaN values to fill\n",
    "            # Interpolate longer gaps\n",
    "            merged_df.interpolate(\n",
    "                method=\"linear\", inplace=True, limit_area=\"inside\"\n",
    "            )  # Using linear interpolation\n",
    "            # Save merged data to a separate file for each ticker\n",
    "            save_data(merged_df, \"data\", stock_symbol)\n",
    "\n",
    "\n",
    "def save_data(data, folder_path, stock_symbol):\n",
    "    folder_path = os.path.join(folder_path, \"production\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    file_path = os.path.join(folder_path, f\"{stock_symbol}_merged_data.csv\")\n",
    "    data.to_csv(file_path)\n",
    "\n",
    "\n",
    "def main_production():\n",
    "    try:\n",
    "        with open(\"ticker.txt\", \"r\") as ticker_file:\n",
    "            stock_symbols = [ticker.strip() for ticker in ticker_file.readlines()]\n",
    "            merge_data(stock_symbols)\n",
    "            print(\"Data saved successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Ticker file not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_production()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This handle misssing values . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dates:\n",
      "DatetimeIndex(['2024-02-27'], dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = r\"D:\\Codebase2.0\\freelancing\\Production_stock_prediction\\data\\production\\AAPL_merged_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "# Define the range of dates for your dataset\n",
    "start_date = pd.to_datetime(\"2021-04-22\")\n",
    "end_date = pd.to_datetime(\"today\")\n",
    "\n",
    "# Generate a sequence of dates covering the range of your dataset\n",
    "all_dates = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Find missing dates\n",
    "missing_dates = all_dates[~all_dates.isin(data[\"date\"])]\n",
    "\n",
    "# Print the missing dates\n",
    "print(\"Missing dates:\")\n",
    "print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
